{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig, BertConfig, BertTokenizer, BertForRetrieval, BertForSequenceClassification)\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckpt_dir = \"/home/transformers-public/output_dirs/sarah-test6/checkpoint-6000\" # Good!\n",
    "# [417, 85]\n",
    "# description [421, 81]\n",
    "\n",
    "ckpt_dir = \"/home/transformers-public/output_dirs/sarah-test7/checkpoint-4000\" # Good!\n",
    "# descruotiib [447, 55]\n",
    "# title only [448, 54]\n",
    "\n",
    "# ckpt_dir = \"../output_dirs/classification_test/checkpoint-4500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(ckpt_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    ckpt_dir,\n",
    "    do_lower_case=True,\n",
    ")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    ckpt_dir,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "if use_gpu:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length=128\n",
    "test_input = tokenizer.batch_encode_plus(\n",
    "    [(\"test input\", None)],\n",
    "    max_length=max_seq_length,\n",
    "    pad_to_max_length=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inp = dict(test_input)\n",
    "model_inp['labels'] = [0]\n",
    "# print(model_inp)\n",
    "model_inp = {k: torch.tensor(v).to(device) for k, v in model_inp.items()}\n",
    "model_out = model(**model_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([]), torch.Size([1, 2]), torch.Size([1, 768])]\n"
     ]
    }
   ],
   "source": [
    "print([x.shape for x in model_out])  # loss, logits, pooled_output (i.e. encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_logits = model_out[1].detach().cpu().numpy()\n",
    "predicted_class = np.argmax(predicted_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43291587 -0.18428318]]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on Doordash Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "dataset = []\n",
    "with open(\"doordash_healthy.csv\", newline='',encoding = \"utf-8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        dataset.append({\n",
    "            'title': row['title'],\n",
    "            'description': row['description'],\n",
    "        })\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "unhealthy\n",
      "healthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "unhealthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n",
      "healthy\n"
     ]
    }
   ],
   "source": [
    "labels = ['healthy', 'unhealthy']\n",
    "\n",
    "counts = [0, 0]\n",
    "for p in dataset:\n",
    "    text = p['title'].lower() #+ ' ' + p['description'].lower()\n",
    "    test_input = tokenizer.batch_encode_plus(\n",
    "        [(text, None)],\n",
    "        max_length=max_seq_length,\n",
    "        pad_to_max_length=True,\n",
    "    )\n",
    "    \n",
    "    model_inp = dict(test_input)\n",
    "    model_inp['labels'] = [0]\n",
    "    model_inp = {k: torch.tensor(v).to(device) for k, v in model_inp.items()}\n",
    "    model_out = model(**model_inp)\n",
    "\n",
    "    predicted_logits = model_out[1].detach().cpu().numpy()\n",
    "    predicted_class = np.argmax(predicted_logits)\n",
    "    \n",
    "    #if labels[predicted_class] == 'unhealthy':\n",
    "        #print(text)\n",
    "    print(labels[predicted_class])\n",
    "    #print(labels[predicted_class], predicted_logits)\n",
    "    counts[predicted_class] += 1\n",
    "    #print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[447, 55]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts\n",
    "\n",
    "# descruotiib [447, 55]\n",
    "# title only [448, 54]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chocolate ice cream\n",
      "unhealthy [[-0.21458574  0.15276423]]\n",
      "\n",
      "big mac\n",
      "unhealthy [[-3.6606882  3.216692 ]]\n",
      "\n",
      "coca cola\n",
      "unhealthy [[-0.39577508  0.39863577]]\n",
      "\n",
      "fried oreos\n",
      "unhealthy [[-0.22029486  0.32009664]]\n",
      "\n",
      "salad\n",
      "healthy [[ 0.56455594 -0.41481605]]\n",
      "\n",
      "ramen\n",
      "healthy [[ 0.63726187 -0.4711248 ]]\n",
      "\n",
      "beer\n",
      "unhealthy [[-0.00074588  0.12836695]]\n",
      "\n",
      "gyro sandwich\n",
      "healthy [[ 0.48251906 -0.34447554]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = ['healthy', 'unhealthy']\n",
    "\n",
    "samples = [\n",
    "    \"chocolate ice cream\",\n",
    "    \"big mac\", \n",
    "    \"coca cola\", \n",
    "    \"fried oreos\", \n",
    "    \"salad\", \n",
    "    \"ramen\",\n",
    "    \"beer\", \n",
    "    \"gyro sandwich\",\n",
    "    \"avoca\"\n",
    "]\n",
    "\n",
    "for text in samples:\n",
    "\n",
    "    test_input = tokenizer.batch_encode_plus(\n",
    "        [(text, None)],\n",
    "        max_length=max_seq_length,\n",
    "        pad_to_max_length=True,\n",
    "    )\n",
    "    \n",
    "    model_inp = dict(test_input)\n",
    "    model_inp['labels'] = [0]\n",
    "    model_inp = {k: torch.tensor(v).to(device) for k, v in model_inp.items()}\n",
    "    model_out = model(**model_inp)\n",
    "\n",
    "    predicted_logits = model_out[1].detach().cpu().numpy()\n",
    "    predicted_class = np.argmax(predicted_logits)\n",
    "    \n",
    "    print(text)\n",
    "    print(labels[predicted_class], predicted_logits)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glisten",
   "language": "python",
   "name": "glisten"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
